{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project I am trying to develop a system that is able to detect human emotion based on a persons voice.\n",
    "\n",
    "I am using a dataset that contains voices of a number people which are labelled by a number of annotators in-terms of the emotions the tone and pitch of these voices indicate i.e anger or happy etc \n",
    "\n",
    "Just like from images these voices are are processed to extract features which a model can understand and use to it for classifications purposes.\n",
    "\n",
    "These features that are extracted include mfcc or Mel Frequency Cepstral Coefficient that indicates the short-term power spectrum of a sound, chroma and mel or Mel Spectrogram Frequency.\n",
    "\n",
    "The zero crossing rate is the rate of sign-changes along a signal, i.e., the rate at which the signal changes from positive to negative or back. This feature has been used heavily in both speech recognition and music information retrieval. It usually has higher values for highly percussive sounds like those in metal and rock.\n",
    "\n",
    "Spectral Centroid, indicates where the ”centre of mass” for a sound is located and is calculated as the weighted mean of the frequencies present in the sound. If the frequencies in music are same throughout then spectral centroid would be around a centre and if there are high frequencies at the end of sound then the centroid would be towards its end.\n",
    "\n",
    "Spectral rolloff is the frequency below which a specified percentage of the total spectral energy, e.g. 85%, lies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "import os, glob, pickle\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(classifier, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    model = classifier.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\" Accuarcy: {}\".format(round(accuracy_score(y_test, y_pred)*100,2)))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\" Confusion Matrix: \\n\", cm)\n",
    "    print(\" Classification Report: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "This block of code defines the method that extracts the\n",
    "features from a particular file.\n",
    "\n",
    "\"\"\"\"\"\n",
    "def extract_feature(file_name, mfcc, chroma, mel, contrast, tonnetz,zero_crossings ,spectral_centroids,spectral_rolloff,spectral_bandwidth):\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X, sample_rate = librosa.load(file_name)\n",
    "        if chroma or contrast:\n",
    "            stft=np.abs(librosa.stft(X))\n",
    "        result=np.array([])\n",
    "        if mfcc:\n",
    "            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result=np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, mel))\n",
    "            \n",
    "        if contrast:\n",
    "            contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, contrast))\n",
    "        if tonnetz:\n",
    "            tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, tonnetz))   \n",
    "        if zero_crossings:    \n",
    "            zero_crossings = np.mean(librosa.feature.zero_crossing_rate(X))\n",
    "            result = np.hstack((result, zero_crossings))\n",
    "        if spectral_centroids:    \n",
    "            spectral_centroids = np.mean(librosa.feature.spectral_centroid(X, sr=sample_rate)) \n",
    "            result = np.hstack((result, spectral_centroids)) \n",
    "        if spectral_rolloff: \n",
    "            spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(X, sr=sample_rate))\n",
    "            result = np.hstack((result, spectral_rolloff)) \n",
    "        if spectral_bandwidth: \n",
    "            spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(X, sr=sample_rate))\n",
    "            result = np.hstack((result, spectral_bandwidth))     \n",
    "    \n",
    "    \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotions in the RAVDESS dataset\n",
    "emotions={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}\n",
    "#DataFlair - Emotions to observe\n",
    "observed_emotions=[ 'happy', 'fearful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "This block of code defines the method that is reponsible for \n",
    "loading the data and extract features for each file.\n",
    "\"\"\"\"\"\n",
    "def load_data(test_size=0.2):\n",
    "    x,y=[],[]\n",
    "    for file in glob.glob(\"archive/audio_speech_actors_01-24/Actor_*/*.wav\"):\n",
    "        file_name=os.path.basename(file)\n",
    "        emotion=emotions[file_name.split(\"-\")[2]]\n",
    "        if emotion not in observed_emotions:\n",
    "            continue\n",
    "        feature=extract_feature(file, mfcc=True, chroma=True, mel=True,contrast=True, tonnetz=True,zero_crossings=True ,spectral_centroids=False,spectral_rolloff=True,spectral_bandwidth=True)\n",
    "        x.append(feature)\n",
    "        y.append(emotion)\n",
    "    return train_test_split(np.array(x), y, test_size=test_size, random_state=9) #Splits the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=load_data(test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288, 96)\n"
     ]
    }
   ],
   "source": [
    "print((X_train.shape[0], X_test.shape[0])) # Overviewing the shape of the training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted: 196\n"
     ]
    }
   ],
   "source": [
    "print(f'Features extracted: {X_train.shape[1]}') # Overviewing the total number of features extracted per sound file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scalling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"This block of code scales the features\"\n",
    "sc = MaxAbsScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " LogisticRegression()\n",
      " Accuarcy: 71.88\n",
      " Confusion Matrix: \n",
      " [[35 15]\n",
      " [12 34]]\n",
      " Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     fearful       0.74      0.70      0.72        50\n",
      "       happy       0.69      0.74      0.72        46\n",
      "\n",
      "    accuracy                           0.72        96\n",
      "   macro avg       0.72      0.72      0.72        96\n",
      "weighted avg       0.72      0.72      0.72        96\n",
      "\n",
      "\n",
      "\n",
      " SGDClassifier()\n",
      " Accuarcy: 48.96\n",
      " Confusion Matrix: \n",
      " [[ 1 49]\n",
      " [ 0 46]]\n",
      " Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     fearful       1.00      0.02      0.04        50\n",
      "       happy       0.48      1.00      0.65        46\n",
      "\n",
      "    accuracy                           0.49        96\n",
      "   macro avg       0.74      0.51      0.35        96\n",
      "weighted avg       0.75      0.49      0.33        96\n",
      "\n",
      "\n",
      "\n",
      " BernoulliNB()\n",
      " Accuarcy: 53.12\n",
      " Confusion Matrix: \n",
      " [[25 25]\n",
      " [20 26]]\n",
      " Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     fearful       0.56      0.50      0.53        50\n",
      "       happy       0.51      0.57      0.54        46\n",
      "\n",
      "    accuracy                           0.53        96\n",
      "   macro avg       0.53      0.53      0.53        96\n",
      "weighted avg       0.53      0.53      0.53        96\n",
      "\n",
      "\n",
      "\n",
      " LinearSVC()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mujtabajavaid/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mujtabajavaid/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/mujtabajavaid/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuarcy: 47.92\n",
      " Confusion Matrix: \n",
      " [[ 0 50]\n",
      " [ 0 46]]\n",
      " Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     fearful       0.00      0.00      0.00        50\n",
      "       happy       0.48      1.00      0.65        46\n",
      "\n",
      "    accuracy                           0.48        96\n",
      "   macro avg       0.24      0.50      0.32        96\n",
      "weighted avg       0.23      0.48      0.31        96\n",
      "\n",
      "\n",
      "\n",
      " KNeighborsClassifier()\n",
      " Accuarcy: 48.96\n",
      " Confusion Matrix: \n",
      " [[24 26]\n",
      " [23 23]]\n",
      " Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     fearful       0.51      0.48      0.49        50\n",
      "       happy       0.47      0.50      0.48        46\n",
      "\n",
      "    accuracy                           0.49        96\n",
      "   macro avg       0.49      0.49      0.49        96\n",
      "weighted avg       0.49      0.49      0.49        96\n",
      "\n",
      "\n",
      "\n",
      " DecisionTreeClassifier()\n",
      " Accuarcy: 69.79\n",
      " Confusion Matrix: \n",
      " [[38 12]\n",
      " [17 29]]\n",
      " Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     fearful       0.69      0.76      0.72        50\n",
      "       happy       0.71      0.63      0.67        46\n",
      "\n",
      "    accuracy                           0.70        96\n",
      "   macro avg       0.70      0.70      0.70        96\n",
      "weighted avg       0.70      0.70      0.70        96\n",
      "\n",
      "\n",
      "\n",
      " GradientBoostingClassifier()\n",
      " Accuarcy: 79.17\n",
      " Confusion Matrix: \n",
      " [[38 12]\n",
      " [ 8 38]]\n",
      " Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     fearful       0.83      0.76      0.79        50\n",
      "       happy       0.76      0.83      0.79        46\n",
      "\n",
      "    accuracy                           0.79        96\n",
      "   macro avg       0.79      0.79      0.79        96\n",
      "weighted avg       0.79      0.79      0.79        96\n",
      "\n",
      "\n",
      "\n",
      " RandomForestClassifier()\n",
      " Accuarcy: 82.29\n",
      " Confusion Matrix: \n",
      " [[42  8]\n",
      " [ 9 37]]\n",
      " Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     fearful       0.82      0.84      0.83        50\n",
      "       happy       0.82      0.80      0.81        46\n",
      "\n",
      "    accuracy                           0.82        96\n",
      "   macro avg       0.82      0.82      0.82        96\n",
      "weighted avg       0.82      0.82      0.82        96\n",
      "\n",
      "\n",
      "\n",
      " XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None)\n",
      " Accuarcy: 79.17\n",
      " Confusion Matrix: \n",
      " [[38 12]\n",
      " [ 8 38]]\n",
      " Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     fearful       0.83      0.76      0.79        50\n",
      "       happy       0.76      0.83      0.79        46\n",
      "\n",
      "    accuracy                           0.79        96\n",
      "   macro avg       0.79      0.79      0.79        96\n",
      "weighted avg       0.79      0.79      0.79        96\n",
      "\n",
      "\n",
      "\n",
      " MLPClassifier()\n",
      " Accuarcy: 66.67\n",
      " Confusion Matrix: \n",
      " [[21 29]\n",
      " [ 3 43]]\n",
      " Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     fearful       0.88      0.42      0.57        50\n",
      "       happy       0.60      0.93      0.73        46\n",
      "\n",
      "    accuracy                           0.67        96\n",
      "   macro avg       0.74      0.68      0.65        96\n",
      "weighted avg       0.74      0.67      0.64        96\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [LogisticRegression(), SGDClassifier(), BernoulliNB(), LinearSVC(),\n",
    "              KNeighborsClassifier(n_neighbors=5), DecisionTreeClassifier(), GradientBoostingClassifier(), \n",
    "               RandomForestClassifier(), XGBClassifier(),MLPClassifier()]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    print(\"\\n\\n\", classifier)\n",
    "    get_prediction(classifier, X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
